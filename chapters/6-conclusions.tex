% !TEX root = ../thesis_main.tex
\chapter{Discussion and Conclusion}
    \label{chap:conclusion}
    \section{Parahydrogen generator and generation}
    The generator previously built in the group worked well and performed at least as good as commercially available devices\cite{noauthor_parahydrogen_nodate-1}. Pressures of up to \SI{50}{\bar} are achievable at parahydrogen fractures above \SI{90}{\%}. Common commercial devices are limited to \SI{10}{\bar} and usually put out pH$_2$ fractions below \SI{90}{\%}. The parahydrogen enrichment was sufficient for the measurements performed and turned out to be reliably above \SI{90}{\%}. It was randomly sampled before or in between measurements to ensure quality. Parahydrogen fractions below \SI{90}{\percent} were only observed after longer storage times in the range of days.
        Filling bottles of parahydrogen on the roof to then use in the lab is a well established practice. Using the new $^{15}$N setup, where high pressures and flows were used, this posed a problem though as bottle volumes often were too small to provide parahydrogen for a long experimental time and showed pressure drops in longer measurements. A steady flow inline pH$_2$ generator would be preferable for this device. As it was ruled out at first because of safety reasons, this should be reconsidered in future. As an intermediate solution, larger pH$_2$ bottles were ordered (\SI{5}{\l} and \SI{10}{\l}) that provide the gas at the desired pressures for a longer time. For convenience and higher safety, the bottles have been fitted with quick connectors. These are attached directly to the bottles instead of the piping (as in previous designs) precluding hydrogen exposure due to mishandling. Connecting and disconnecting the bottles is now an easy task due to the now pressureless design of the quick connection. This eliminated leakage of the bottles.
    \section{Low field spectrometer}
        The previously built low field spectrometer was used in many of the different measurements described in this work. More coils were built - on all fronts - i.e. field generation, transmit and receive coils. The previously existing software was adapted to the current needs and more features were added. A discussion on what was improved, added and  what was discarded is provided here.
        \subsection{$B_0$ field generation}
        Multiple coil designs of the coils generating the static magnetic field have been considered, simulated, built and tested in the course of this work. The previously used solenoid design with different lengths of compensation windings (see section \ref{sec:results:sim:B0}) showed rather broad lines in the range of several \SI{100}{\hertz} in both simulations and measurements. The main reason is the discrete number of compensation windings that do not allow for a tuning of the coil fine enough to generate more homogeneous fields. This could be improved by putting the compensation windings on sliders that can be moved in the z-direction. Separating power sources for main coil and compensation windings allowing for individual currents through both coils would also improve the flexibility and thus homogeneity. Additionally, in the design used, mechanical errors in the production increased the problem of inhomogeneity. Due to the high number of windings guided only by the previously wound wire, shifts building along the coil's z-axis are inevitable. In addition, layering the wire leads to slippage into the gouge created by the previous layer. An additional test using rectangular wire instead of round for both better filling factors and more precise winding was too difficult in terms of manufacture. The problem may be solved by using a thin, but stiff layer of material to separate the wire layers from each other. All of the mentioned solutions are inconvenient though when considering the dimensions of the coil and different approaches such as the dual Helmholtz coil mentioned later in this section had to be considered.
            The heating of the solenoid coil led to an additional problem: Field shifts, probably due to the thermal expansion of the copper heating by $\Delta T = \SI{40}{\kelvin}$ for the \SI{35}{\centi\meter} long coil leads to an expansion of 
            \begin{equation}
                \Delta x \approx \alpha \mathrm{L}\Delta\mathrm{T}= \SI{16.5e-6}{\per\kelvin}\cdot \SI{40}{\kelvin} \cdot \SI{0.35}{\meter} = \SI{0.2}{\milli\meter}
            \end{equation}
            This elongation induces a clearly visible frequency shift that can be problematic for measurement reproducibility (compare also to simulations of sub-millimeter positioning errors, figure \ref{fig:results:fieldSpread}).
            To avoid field shifts during measurements, the setup should therefore be in thermal equilibrium. This is especially relevant when switching fields quickly during measurements using the programmable power supply after which this equilibrium is usually shifted to a different temperature. After every switching, a drift towards the new equilibrium can be observed via the frequency.
            Positioning of the coil to reduce external influences was considered, and the best way is to keep it away from the ground (concrete reinforcement rods) and normal cupboards and tables as usually ferromagnetic parts are used in almost all constructions. An aluminium-PVC construction was used here but also wooden parts can be considered. Especially connecting elements such as screws and elbows, end caps and locks and also glues and coloring need to be tested for their influence on the magnetic field. If a high field magnet is available, a good measure for field disturbance is the attracting force in its stray field. If no force is measurable, the influence on the low field coil can be considered negligible.
            The dual Helmholtz array design deals with many of the above mentioned problems of field inhomogeneity due to manufacturing errors. The single coils are wound onto a milled holder making moving in z direction possible and convenient. Sub-millimeter precision was strived for and verified experimentally through the narrow lines in the \SI{10}{\hertz} regime corresponding to the simulation results. Due to the shorter extension of the coils in z-direction in combination with the precisely milled holders, the errors introduced in the winding process are smaller than for the solenoid. Using PVC foil to separate the axial layers kept them from slipping into the gaps of the previously wound layers adding to both radial and axial precision. The rather narrow, laser cut PVC layers were easily installed compared to the large area foil necessary for a more precise solenoidal design.
            In addition, the more open design allows for axial access to the sample which can make experiments a lot more convenient as for example decoupling of B1 and receive coil do not need to be performed through the narrow opening of the B0 solenoid coil. The disadvantage of the design are the higher currents due to the lower overall winding count combined with larger distances to the measured object, which requires a higher electrical current to generate the same magnetic field as the solenoid coil. In this case, a \SI{5}{\milli\tesla} field generated using a commercially available, four channel, 32V/10A power supply was sufficient though (section \ref{sec:matMeth:Helmholtz}). Should the availability of high current power supplies be the limiting factor, but the Helmholtz design is preferred over a solenoid one, more windings per pair could be considered. This would probably reduce homogeneity due to the resulting larger geometric extent, but may still be more convenient and more homogeneous than a solenoid. Furthermore, the addition of a third coil pair or one central coil can be considered. All new designs can be easily simulated using the developed modular code.
        \subsection{RF-Signal amplification}
        The low voltage and especially low current signal output of the NI-card did not suffice to create Flip angles in the 90/180 degree range for the coils used in the setup. As shown in \ref{chap:results:lowFieldNMR} and described in \ref{sec:matMeth:lowFieldSpectrometer} and \cite{borowiak_battery-driven_2013-1}, audio amplifiers were used to amplify the signal according to the requirements. These amplifiers were a cheap and easy solution, but were not built for this task: Their frequency range does not cover the Larmor frequencies of protons of approximately \SI{250}{\kilo\hertz} at \SI{5}{\milli\tesla}. The drop in performance at those frequencies especially for higher voltages is thus not surprising. Generally, the audio amplifier used was at its power limit and prone to overpower-shutdowns - for future setups and especially more complex and demanding sequences, a dedicated amplifier delivering the power necessary more easily has to be considered.
            An amplifier from a decommissioned setup at a neurology workgroup was gifted to our group. It covers the frequency range necessary but was not recommissioned yet. Many of the problems introduced by using an audio amplifier like switching off due to overload and the limitations due to the operation above the amplifiers upper frequency limit should be solved once it is installed.
        \subsection{$\mathrm{B}_1$ coils}
        The B$_1$ coils show a broadband behavior as intended and expected. 180 degree flip angles were well possible if the coil voltage was not too high, i.e. if the pulses were long enough. Exceeding the voltage limit causes arcing especially inside the capacitors used which cuts the effective coil voltage at the peaks of the sine. Additional effects such as ionization of the gas inside the capacitors may lead to the behavior shown in chapter \ref{sec:results:receiveCoil}, i.e. a more a less constant flip angle, but with a large error.
            The matching of the $\mathrm{B_1}$ coil depended on its geometric orientation towards the receive coil due to inductive coupling of the two. A pin diode design to actively detune the receive coil during pulse transmission would be beneficiary as both the flip angle would be more reproducible as the energy lost in the receive coil is then rather constant and waiting times after pulsing would reduce as the energy stored in the resonance circuit would be lower. The implementation of such a decoupling during pulsing is now easily possible with the new control program as the analog output can be used in the background while other tasks such as digital output switching are performed.
            B1 homogeneity was not explicitly evaluated. To be sure the whole probe volume is excited, this could now, after gradient coils for the setup have been built, be probed with sequences adapted from high field imaging devices.
            Experiments with printed circuits on copper foil for etching were unsuccessful due to printer heating problems (the copper foil cooled the laser printer's fixation roll too strongly), but may greatly improve the coil's geometric accuracy compared to the rather complicated winding process used up to date. Should printing not be an option, standard etching on copper foil or ordering the circuits pre-etched onto foil would be an option.  The design for these circuits can be found in the appendix, figure \ref{fig:appendix:saddleCoils} (b).
        \subsection{Receive coils}
            The resonances measured with a dedicated network analyzer showed peaks very different from the resonances measured with the NI card used in the experiments. As the more relevant resonance frequency is the actual frequency during measurements, the NI-card's result was used to setup the coils. It has to be considered though that the network analyzer provides a more realistic result of the coil's intrinsic resonance frequency. For future builds, network analyzer results and calculations can be considered for a first estimation, but fine tuning has to be done with the measurement card itself. Generally, it would be beneficial to use the higher Q resonance shown in figures \ref{fig:results:networkAnalysis} and \ref{fig:results:niNetworkAnalysis}, but the behavior described above leads to the use of the lower Q resonance during the measurements performed in this work.
            While single channel coils are well suited for low field experiments, dual channel coils often show lower performance and sensitivity on at least one of the two channels and a two channel setup is often preferable to a dual channel one (see methods, sec. \ref{sec:matMeth:receiveCoil}). The measured Q-factors (see sec. \ref{sec:matMeth:receiveCoil}) were well within the range that delivers acceptable SNR in the high volume samples usually used (i.e. multiple millilitres). If smaller volumes should be measured, either Q-factors of the circuit's components need to be improved or the use of differently shaped coils (e.g. microcoils) must be considered.
        \subsection{Shims}
            The linear shims built for the low field unit work as intended and reduce linewidths significantly. For future builds, higher order shims should be considered as the field distribution of the solenoid coils - looking at both simulations and linewidths - seemed to have large quadratic contributions. Thus, linear shims did improve linewidths slightly but were not able to get beyond linewidths of \SI{50}{\hertz}. Considering the low fields, this is rather large, corresponding to 200~ppm spectral resolution. This point is supported by the fact that the two more parabolically shaped fields of the Helmholtz pairs provide narrower lines to begin with, without additional shims (although one could consider one Helmholtz pair as the field generating one and one as a quadratic shim). The shim tool implemented into the existing Matlab data recording tool is working well and finds the same settings for minimal linewidths from different starting points and through different iterations. Shifting of shim polarity was implemented using relay switches but could be improved using MOSFETs that are faster, more efficient and more quiet.
    \section{In-situ SABRE in water}
    The method described by \cite{truong_irreversible_2014-1} was successfully implemented on our low field spectrometer in a continuous fashion. By doing so, buildup times could be determined and sample lifetimes could be estimated.
        \subsection{Buildup times}
            Knowledge of the buildup times is key for maximizing the signal output in consecutive measurements, similar to the Ernst angle in thermally polarized measurements. As the mechanism is different from a pure T$_1$ decay, the buildup times will differ from T$_1$ times as well.
        \subsection{Sabre in cell culture solution}
        \label{sec:discussion:cellSolution}
        The addition of Dulbecco's Phosphate Buffered Saline (DPBS) cell culture solution depleted the signal very quickly, after addition of only \SI{1}{\milli\liter} DPBS, the previously well visible signal was not detectable any more. The problem is probably the addition of paramagnetic molecules. As the hyperpolarization process relies on the interaction of pH2, the Iridium catalyst and the molecule, the addition of other (magnetic) substances can easily disturb these processes by either hindering the formation of the complexes or its intermediates or by relaxation of the hyperpolarized molecules after contact with the catalyst. Different solutions to the problem come to mind: 
            \begin{itemize}
            \setlength{\itemsep}{-7pt}
                \item Using different catalysts less prone to disruption by external molecules.
                \item Using more dedicated readout techniques that detect lower signal
                \item Finding molecules less affected by the relaxation agents
                \item Hyperpolarizing other nuclei that have higher signal or less background signal
            \end{itemize}
        \subsection{Sabre in blood}
        The fact that signal is depleted upon contact with blood very quickly and very strongly, even with the low amounts of blood used in this work makes the vision of in vivo measurements vanish out of view. As described in the previous section, there are a few solutions to consider to get around the problem of signal loss, but it remains uncertain if any of these will provide salvation for the rather serious problem. Two alternative seem promising:\newline
        1.: Encapsulation of the hyperpolarized solution only to be released at the site of interest see next section \ref{dc:subsec:liposomes}.\newline
        2.: High batch polarization that is sufficient to provide signal at the site of interest despite relaxation, i.e. that is still sufficiently hyperpolarized at that point.
        \subsection{Liposomes and SABRE}
        \label{dc:subsec:liposomes}
        To address the first solution mentioned above, experiments together with the clinic's chemical department were performed. The results from these experiments did not yield the desired effect and were thus not carried further. As it seemed that the components used for encapsulation of the sample solution already had an effect similar to that of the cell culture solution or the blood, the intended effect, even if encapsulation was successful, was not achieved. Other encapsulation methods that do not show such a strong negative influence on the signal should be considered in future. The process of elimination for testing purposes that was supposed to be used for the liposomal solution can be reutilised in these scenarios, i.e. testing the whole solution for hyperpolarized signal, then filtering the catalyst from the volume surrounding the capsules before also filtering the substrate from the surrounding volume. To reduce workload on components that will not provide the desired effect, testing of the individual chemicals' relaxation effects on a working, hyperpolarized solution can be beneficial.
        \subsection*{}
        The methods described here proved to be limited in their in-vivo application. By now though, new, intrinsically water soluble catalysts have been synthesized \cite{spannring_new_2016} that can potentially resolve some of the issues described above. Measurements performed here can be repeated using the more advanced catalysts to see whether catalyst deactivation was a cause of the described signal loss.
    \section{Imaging at earth magnetic field}
    While the signal of the hyperpolarized solution and thus its SNR was high compared to the water sample, it has to be considered that the pre-polarization magnetic field was only \SI{5}{\milli\tesla} and thus nearly three orders of magnitude below the field strength of commercially available MRI systems. At higher magnetic fields for readout, hyperpolarized signal would remain fairly constant (neglecting changed relaxation effects). Thermal signal of the pure water would increase linearly with the field though and thus, a standard high field image is to be preferred over the low field hyperpolarized signal considering signal amplitude only. If, though, a metabolic process could be monitored with the hyperpolarized nicotinamide, the setup would allow for doing this with the low concentrations provided and fairly low signal background. Furthermore, the signal increase can be used to build cheap low field imagers in specific fields such as transportable machines or low cost machines e.g. for developing countries. Here, the rather complicated procedure has to be considered though and a system that is more automated would be necessary.
    \section{Sabre shuttling system}
        The system was designed to perform measurements in a well reproducible setting. As all shuttling and even scanner control are automated, volume shifts and timings are very well reproduced within consecutive scans. A measurement of those timings was not performed as the error is small compared to the error introduced by fluid loss, fluid flow and bubbles in solution.
        \subsection{15N phantom}
        The glycine phantom was made from $^{15}$N glycine obtained from a laboratory closing for free in contrast to buying expensive 15N-labeled pyridine. For adjustments, a $^{15}$N-pyridine phantom would have been preferrable due to the relatively large frequency shift of \SI{12000}{\hertz} between the two. The doping with Magnevist to substantially reduce T$_1$ and thus the waiting times especially during shimming but also doing adjustments worked as intended, with no observed drawbacks (e.g. too low T$_2$ or else). TR could be set to \SI{300}{\milli\second} which shows T$_1$ is in the \si{\milli\second} range compared to a T$_1$ of \SI{50}{\second} using the undoped substance.
            By enclosing the phantom without any air in a glass vial, the phantom stayed mold-free over the course of three years up till today.
            The disadvantage of not using the substrate that is measured in the experiments is the rather large frequency shift of \SI{12000}{\hertz} at \SI{9.4}{\tesla}. This means that adjustments such as flip angle calibration and match are slightly off, considering the wide resonance peak of the coil (see section \ref{sec:results:receiveCoil}), the induced error is acceptable.
            Furthermore, the shim on the phantom does not include the geometry of the hyperpolarized sample as the closed vial will not fit the high field reactor. Thus, the shim of the hyperpolarized sample is worse than that of the phantom despite its smaller overall volume.
            What posed a problem at first was physical deformation of the coil leading to detuning and -matching when switching from phantom to reactor. This is easily solved by supporting the reactor from the bottom, but has to be considered when measuring with the setup.
        \subsection{Components manufacture and durability}
        \label{sec:discussion:componentsAndDurability}
            The choice of material for manufacture seemed reasonable as PSU has a high tolerance for most solvents such as methanol, ethanol or isopropyl and shows high resistance to mechanical stress, too. Later, during a calibration measurement with neat pyridine, it was observed, however that PSU is not resistant to pyridine. For low concentrations usually used in the experiments, this does not pose a problem as far as we know but still, other materials such as PEEK should be considered in future. These materials have other disadvantages, PEEK for example is opaque aggravating the bubbling and sample control. The design of the components took ease of manufacture into account in order to keep manufacturing delays to a minimum.
            Mechanical durability for the PSU components was excellent through all measurements. Acetone should not be used for cleaning purposes as it cracks the material immediately - as accidentally demonstrated on a previous setup in our group. The component most prone to failure was the screwed ferule fitting of the capillary for fluid transfer. As it was under constant pressure change and the mass of the fast flowing sample moved it considerably during shuttling, it failed three times during measurements resulting in loss of sample. A flanged connection according to \cite{noauthor_finemech_nodate} should provide a remedy to the problem though. The special tool to handle the capillary and other tubing accordingly is available and will probably strongly increase the long term stability of the connections.
            O ring choice is important as the standard nitrile rubber (NBR) material is not resistant to ethanol which is a problem both because of o-ring failure and signal relaxation via the dissolved material. NBR rings left residue in the reactor that seemed to deteriorate the signal, as, upon reactor cleaning, signal always improved. Using fluoroelastomers (FKM) as the o-ring material resolved this issue, the signal did not deteriorate even if the same o-rings were used over days of measuring without cleaning the reactor.
        \subsection{15N coil}
            The layout designed for the $^{15}$N coil is well suited for usage in a small animal imager. The trimmer capacitors aligned parallel to the scanner bore are accessible from the outside using rods, i.e. while the coil is installed, for efficient tuning and matching. Generally, an improved design would feature rod guides to access the trimmer capacitors even more easily. The current design requires some fiddling to insert the rod into the capacitors slit, especially over the distance of $\approx$ \SI{1}{\meter} in low light.
            The tuning capacitor covers a range that enables measuring at both the \SI{9.4}{\tesla} and \SI{7}{\tesla} imagers. As the range is large, small turns cause large shifts, should the coil be used primarily at one of the scanners, using a smaller range could be beneficiary for easier adjustment.
            The Q-factor of the coil is in the range of commercially available coils and thus delivers reasonable SNR.
            A downside of the coil is that, at power levels well below the maximum power output of the RF-amplifier, the coil starts to spark. In this case, the sparking can be observed visually and occurs mostly in the capacitors. This means that a maximum power level is defined intrinsically by the coil making very short, strong pulses impossible. The problem has previously been solved by many coil and/or capacitor manufacturers. Using different dielectrica or build geometries of the capacitors, sparking can be reduced or avoided completely. As these high end, specialized capacitors are much less readily available and, at the moment, there was no need for very short pulses, standard capacitors were used during measurements shown in this work.
        \subsection{Valves and valve control}
            Valve control using the teensy microcontroller rendered the whole setup versatile and flexible. 8 programmable buttons (extendable to 16) can control either individual valves, trigger a scan, or play sequences of both. Additionally, pressure in the system can be used as a parameter for valve opening and closing and more parameters can be fed to the teensy if needed. This makes the system more adaptable to different scanners and valve setups. In future builds, the relay used for switching could be replaced by MOSFETs for faster and more efficient switching. 
            The \SI{230}{\volt} AC valves were chosen to make power supply easy through the mains power. While the valve switching itself was facilitated by that choice, the high inductances and high voltages in combination did have a considerable influence on the electronics, probably through inductive coupling of peak currents in the valve lines. This led to unexpected behaviors that could only be solved by inserting dead times after switching of the valves slightly reducing the timing resolution of the setup. \SI{24}{\volt} DC valves have been ordered together with a DC power supply to replace the current valves. A second problem solved by a 2 staged frequency filter was unexpected triggering of the scanner following a valve switch. This solution proved to work constantly over all the measurements and while timing resolution was worsened slightly by the filter, other effects were more relevant, especially considering reproducibility of fluid transfer. The filter can likely be removed after exchanging the valves for the \SI{24}{\volt} version though. Using MOSFETs instead of relay might also solve this problem as relay show fairly high intrinsic inductances that are are obliterated in MOSFETS. 
            Some problems occurred with the solenoid valves: after about two years of usage, two of the valves started humming strongly, one of the two failed to open and shut properly as well. As the maximum pressure of the valves was not exceeded and valve directions were considered during assembly, the cause of the error is unknown. The valves were exchanged and contact to the manufacturer has been established to find the source of the failure.
        \subsection{Parahydrogen supply and bubbling}
            Parahydrogen supply was ensured as long as the pressure in the bottle did not drop below the working pressure. The bubbling disk fulfilled its purpose well and previous concerns of undefined volumes of fluid remaining below the disk in the cone shaped cover were not met upon visual inspection. The later described flow channels building can possibly be reduced or prevented by changing the geometry of the bubbling disk. This is easily possible due to the modular setup of the design. A different disk could feature more or less holes in larger or smaller diameter, a prediction of what is preferable is difficult due the turbulent flow of both the gas and the fluid. It will probably change with fluid volume, pressure and density and viscosity of the sample as well. Empirical testing is required if one of the parameters is changed strongly.
            The design of the upper part of the low field reactor led to a strongly reduced loss in fluid due to bubbling as the diameter expansion led to bursting of large bubbles rising inside the reactor as intended in the design. They seemed to be a primary source of fluid loss when reaching the opening connecting to the vent or needle valve.
        \subsection{Mu metal shielding}
            The shielding provided fields below the theoretically necessary values as was intended so that optimal fields could be reached using an additional coil inside the shield. Moving the shield too close to the scanner would raise the fields above the optimal values for $^{15}$N polarization. A distance of $\approx$ \SI{2}{\meter} to the bore proved to be a good measure to keep fields below $\approx$ \SI{100}{\nano\tesla}. This of course changes with the active shielding of the scanner and hence with its stray field. At the \SI{7}{\tesla} MRI machine, a position much closer to the scanner was possible and desirable due to relaxation effects at low fields. Generally, the danger of the shielding being attracted to the magnet must be considered and safety measures must be employed (e.g. limitation of the movement radius through tension belts). The size of the shield is the second largest standard shield size delivered by the Mu metal shielding manufacturer. To increase field homogeneity (through larger diameter coils) or have more equipment fit the shield, the larger sized shields are an option. Furthermore, individual builds (yet at probably much higher cost) can be considered.
            The degaussing unit built by the workshop proved to be more reliable and delivered more consistent fields than the previously used power supplies used to manually reduce the current. Multiple magnetization (in the scanner stray fields) and degaussing cycles delivered the same field values measured inside the shield afterwards. The slew rate of the current during degaussing can now be set individually for different shields and according to manufacturer specifications. In our case this was \SI{0.25}{\ampere\per\second}. Automatic calibration of the currents for new shields according to this rate made usage very convenient.
        \subsection{Low field manipulation}
            As previously mentioned, the fields inside the shield were lower than the optimal field values for $^{15}$N hyperpolarization. The coil installed in the shield is of the same design as the dual Helmholtz set described in the low field spectrometer section (\ref{sec:matMeth:lowFieldSpectrometer}). It generates fields homogeneous enough to leave the whole sample in regions of at least \SI{95}{\%}of the optimum magnetic field. That is true for a setup outside the shield. Inside the shield, an influence of the high susceptibility cannot be precluded, though measurements show that position changes of the low field reactor do not influence signal strongly implying that homogeneity suffices to cover the sample volume with acceptable magnetic field values. The fields inside the shield, measured with the fluxgate sensor, differed for solenoid and Helmholtz coil, the field/voltage slope rose faster for the solenoid. This is expected due to the smaller distance especially of the central windings of the solenoid coil. Partly, the Helmholtz assembly compensates for this through more radial layers, but does not reach the field intensity the solenoid does. The slope difference of about a factor of 4 has to be compensated by the higher currents in the Helmholtz assembly. A simulation including the shielding layers would help understanding the resulting homogeneity but is quite complex as iterations over fields would need to be performed until the change in the region of interest is small. As fields seemed homogeneous enough, this was not implemented. For setups with smaller coil diameters and smaller shields that are more portable, theses simulations would help estimating the feasibility.
        \subsection{Temperature control}
            \label{cd:sabreShuttling:tempControl}
            Temperature is the one factor that is both not controlled and also very difficult to control in this setting. Wall thickness has to be in a range that withstands the pressures used in the setup and thus makes all indirect heating through the walls difficult, especially since the fluid volume is small compared to the PSU volume surrounding it. Temperature measurement would be easily possible through optical, contactless sensors, but temperature control is not solved. Optimal temperatures for the IR-IMes/Methanol/15N-pyridine mixture were shown to be at around \SI{14}{\celsius}. As these temperatures are below laboratory AC temperatures of \SI{18}{\celsius} and the parahydrogen flow decreases the sample's temperature, the optimal temperature was reached (experiments show temperature decreases towards \SI{0}{\celsius} under constant flow), but may well be undercut. As temperature is not controlled or regulated in the current setup, a sleeve for a cooling or heating liquid may be considered in future designs. One implementation has been designed, but was not manufactured and is shown in figure \ref{fig:conclusions:tempSleeve}. The design is intended to be flow based and low pressure, existing animal bed heating devices could be used with this implementation. Equally, the high field sample container could be heated too to avoid cooldown during readout. Here, a slightly more advanced design featuring the solenoid coil would be preferable so that the filling factor isn't decreased.
            \begin{figure}
                \includegraphics[width=0.9\textwidth]{/figures/conclusions/temperatureSleeve.pdf}
                \caption[Temperature sleeve]{A possible realization of a temperature sleeve for the low field reactor. The same design could be used for the high field probe container but would need to include the high field coil to keep the filling factor high.}
                \label{fig:conclusions:tempSleeve}
            \end{figure}
        \subsection{Automated hand valve}
            The low volume hand valve worked reliably throughout the measurements. As the adaptor connecting servo and valve was forged by hand, collinearity of the axes was not given and led to a slight wobble of the setup during the moving of the valve putting strain on the fixation screws. Here, a future design should be either 3D-printed or milled to make for a better axial alignment to ensure long term stability. Same goes for the basis onto which both the valve and the servo driver are mounted.
            \begin{figure}
                \centering
                \includegraphics[width = 0.99\textwidth]{/figures/conclusions/servoAdaptor.pdf}
                \label{fig:conclusions:servoAdaptor}
                \caption[Servo adaptor]{The suggested bent design for a better connection of servo motor and hand valve. Dimensions are chosen so the currently hand valves fit the mold. A 3D print of the adapter can also be considered.}
            \end{figure}
        \subsection{Shuttling speeds}
        The duration of the shuttling procedure was short enough to keep hyperpolarization at levels sufficient for parameter analysis and polarizations in the range previously reported. At higher pressures (or using larger diameter transfer capillary) shuttling speeds can be increased. For ease of use, the same capillary resisting the highest pressures has been used for all measurements. For future setups, an additional field that can be switched on before shuttling should be considered as T$_1$ relaxation at \si{\nano\tesla} fields is a lot faster ($\approx$\SI{1}{second}) than at higher fields (10s of seconds). Fields of \SI{1}{\micro\tesla} suffice to increase relaxation times (pyridine in methanol) to \SI{30}{\second}. The field could be generated by a wire wound around the reactor and transfer capillary. The current it would need to carry is relatively low due to the closeness to the tube. Field homogeneity is not an issue as long as the field is high enough at the center of the tube. At the point at which the capillary leaves the mu metal shielding, the stray field of the scanner is large enough to protect the solution from quick relaxation.
        \subsection{T1 and T$_2$ measurements}
        The values measured for T$_1$ correspond well to the values measured in literature before. The slightly longer T$_1$ for MeOD as a solvent is due to the reduced number of interacting proton spins in contact with the substrate that would otherwise increase relaxation. T$_2$ is shorter than expected and it is especially short for imaging sequences. Thus, either the molecule used needs to be exchanged (which makes sense due to the missing metabolic relevance of pyridine) or other parameters need to be changed to effectively image the substrate. For a Flash image, the T$_2$ sufficed, but for longer imaging sequences e.g. to display  metabolic processes this would be a problem.
        \subsection{Shuttling reproducibility}
            As shown in section \ref{results:15N:shuttlingReproducibility}, the relative error on the shuttling process is low. It has to be considered though that a completely dried system will reduce the amount of substance arriving on the high field side by a non negligible amount by humidification of the surfaces. That is why, depending on the previous state of the system, a drop in signal could be observed during the first or first two shuttling procedures. After that, the only source of fluid loss is the evaporation of liquid during bubbling - leaks of fluid have not been observed unless a seal failed. High flows generate high polarization  and signal yield up to a certain point. At the same time, large losses in fluid volume over short periods of time occur if the flow is too high. Therefore, for parameter optimization, usually  a lower flow rate was chosen to make consecutive scans more comparable in terms of volume and thus signal. The signal scaling with flow should be independent of the other parameters and can therefore be adapted accordingly.
        \subsection{Pressure dependence}
        Polarization shows a linear dependence on pressure in the measured range. This indicates that higher pressures would still increase the signal as a plateau is to be expected where a higher pH$_2$ concentration in solution does not increase the number of complexes with bound pH2. This happens if pH$_2$ is more readily available than oH2 from relaxation or from complexes after conversion, i.e. if $[pH2]>>[oH2]$. Increasing pressures further in future setups is certainly possible considering the currently rather thin \SI{5}{\mm} walls of the PSU reactors. One limitation that occurs are certainly the screwed ferrule connections of the capillary and PTFE tubing which, under high pressures can slip out of its fits. It can be replaced by more sophisticated flanged ferrule connections which require special tools that are commercially available though. Larger inner diameter tubing also starts to reach its pressure limitations above \SI{50}{\bar}, but can easily be replaced by tubing with smaller inner diameter. Reduced flow through these tubing will, on the one hand, be compensated by the higher pressure differences themselves, on the other hand, the only fluid pathway is already covered by a small diameter capillary resisting pressures up to \SI{200}{\bar} according to its data sheet.
        \subsection{Field dependence}
        The dependence on the magnetic field shows a pattern of two peaks around a minimum with signal going towards zero in the outskirts, i.e. towards high fields. This makes sense as simulations suggest fields around \SI{300}{\nano\tesla} delivering the energy splitting range in which level anti crossings are fully developed. The shield is thus efficient enough to generate sufficiently low fields for optimal results. The overall field depends on the residual magnetization of the mu metal shielding and is measured independently. That makes direct comparisons difficult as the shield needs to be opened to change from measurement head (fluxgate) to the polarization system. During that exchange, magnetization of the shield can change by mechanical stress such as hits to the shields or lids or by external magnetic fields reaching into the inner shields and leaving residue magnetization even after opening. The asymmetry of the distribution is due to residual magnetic field of the shield. It generates both a shift of the 'mirror axis' which indicates the voltage at which the lowest field is found  and an overall deformation of the distribution depending on the field homogeneity.
        \subsection{Concentration dependence}
            The concentration plays an important role in the SABRE complex formation, the formation of different intermediates and also the dissociation of the complexes. Generally, a substrate concentration that is large compared to the catalyst concentration will lead to a reduction in polarization as the pool of substrate molecules in solution is large compared to those in bound form. Therefore, the relaxation of the substrate pool will be more effective because a smaller fraction of the substrate is repolarized at the catalysts. This can be seen in the data, as a reduction of the relative concentration of substrate leads to a signal increase. Catalyst concentration remains constant in the example given.
            \begin{equation*}
                [\mathrm{IrIMes}] = \mathrm{const};~[\mathrm{MeOD}] = \mathrm{const};~[\mathrm{15N-Py}]~\mathrm{reduced}
            \end{equation*}
            This means that, although the overall amount of substance of the substrate does not change, more molecules are hyperpolarized at the same time and thus a larger magnetization is generated. Note that here, in contrast to spectrometer measurements, the complete sample is inside the sensitive volume and thus the signal increases with increasing dilution. This effect compares well to other results in literature \cite{barskiy_simple_2015}. Polarization, which is often used as a quality indicator for the hyperpolarization process, can be increased by reducing the substrate concentration. At the same overall sample volume though, this will not necessarily increase the signal.
        \subsection{Flow dependence}
        The flow has a strong effect on polarization as the effective parahydrogen supply depends on its availability at the surface of the perfused sample solution. First, the signal increases with parahydrogen flow. It shows though that there is a flow limit above which increasing flow does not increase signal. This can be explained by the fact that not only the speed of parahydrogen flow, but also the surface to volume ratio of the sample. At low flows, bubbles form in the intended way through the installed bubbling disk or simply at the end of the parahydrogen supply channel. If the flow is increased too far though, consecutive bubbles will not be separated any more and flow channels will form. That reduces the surface area through which hydrogen diffuses into the solution and thus signal does not increase further despite the larger general availability. This flow channel formation could be seen by visual inspection.
        \subsection{Polarization and magnetization}
            Polarization reached levels in the previously reported ranges while magnetization was high considering the high concentrations of \SI{50}{\milli\molar}. In many publications, researchers seem to try and maximize polarization - in this work, magnetization, i.e. absolute signal intensity was considered more important as for any future application, this is the relevant parameter for maximizing the signal. Considering the concentration used here, the polarization surpasses previously reported values and makes the setup suitable for batch polarization for future use in imaging experiments. While this sounds promising, of course the same problems that arose when hyperpolarizing $^{1}$H samples may occur here as well: relaxation in-vivo will probably be significantly faster, even at high magnetic fields.
    \section{Fluxgate}
        The DC-DC converter showed low tolerance to power overload. A failed one had to be replaced.
        The readout of the fluxgate electronics works consistently after solving initial problems which occurred with the analog switches used in the final design. The problems were probably due to careless testing of the board leading to short circuiting and destruction of some of the switches. These defective parts have been replaced by new ones and the device has been running fault-free since.
        The amplifications used for the operational amplifiers are currently not covering the largest range possible - a better choice of resistor ratios is shown in table \ref{table:discussion:amplifications} together with the currently installed resistors.  Resistors with the high precision values deemed necessary here were not available which is why the setup is still in the old setting. Especially for low fields, the discretization of measurement values was observable though introducing an additional error on the field measurement.
        \begin{table}
            \centering
            \begin{tabular}{|c|ccc|ccc||rr|}
                \hline
                OP Amp \# & 0 & 1 & 2 & 3 & 4 & 5 & min amp& max amp\\
                \hline
                resistor ratio & 1 & 4 & 16 & 1 & 4 & 16 & 1 & 256\\
                wider range ratios & 1 & 4 & 16 & 1 & 64 & 1024& 1 & 16384\\
                \hline
            \end{tabular}
            \begin{tabular}{|c|cccccccc|}
                \hline
                current amplifications & 1 & 4 & 16 & 64 & 256 & & & \\
                possible amplifications & 1 & 4 & 16 & 64 & 256 & 1024 & 4096 & 16384\\
                \hline
            \end{tabular}
            \caption[OP-AMP amplifications]{Amplifications of the individual OP-Amp assemblies. Note that in the old setting, the amplification range was 256, whereas for the more widely ranged setting, it is 16.384. The amplification range is raised while keeping the lower amplification steps at the same distance. Note that this highest amplification probably does not make sense due to the high error.}
            \label{table:discussion:amplifications}
        \end{table}
        \subsection{PCB design}
            The PCB design using the - up to that point - open source software was quite comfortable. By now, the Eagle software has been bought by Autodesk, older versions still work though. The designed PCB was checked by our workshop before production to make sure components were chosen correctly. That way, the development could start immediately though limiting the chance of errors. Manufacture of the PCB was precise and error free, probably cheaper alternatives can be used, but delivery times are usually longer then. Using soldering stop should be considered in a new version to keep shorts between the small footprint components to a minimum.
        \subsection{Sensor calibration}
            Calibration was easily possible in the setting used here for two directions (x- and y) whereas the z direction required improvisation as a rotation was not possible along either x or y axis due to geometric constraints. The error of the calibration was in the range of the sensors intrinsic error according to the data sheet. A larger range of fields for calibration - especially in z direction - might be beneficiary for the result.
            The overall results show that through a combination of positioning errors, intrinsic systematic sensor errors and possibly also magnetization changes in the field, the value of the field was reproduced within an angular range of $\approx$ \SI{4}{\degree} and an absolute range of \SI{3}{\nano\tesla} between different measurements. This is completely sufficient for our purposes where a precision of \SI{20}{\nano\tesla} will be enough to keep field parameters within the optimal range.
        \subsection{Sensor positioning}
            As the sensor position is very relevant, it had to be reproducible. At the same time, it should be possible to change the position to measure at different points inside the shield or coil. The assembly enabling this was designed around the coil and works reasonably well as long as the sensor is inserted more than \SI{1}{\centi\meter} into the holder. The holder, based on a form fit connection, did not lose its fit over moves between measurements ranging in the hundreds. Height adjustments were possible from the top access of the shield, but could be improved by exchanging the screws for tool free thumbscrews. Positioning errors of the sensor were in the millimeter range. The angular error was about \SI{3}{\degree} as the readout from above was difficult even with additional lighting.
    \section{Summary}
    Within the scope of this work, different SABRE hyperpolarization methods have been used and optimized. Many different coil designs have been simulated, built and tested for all kinds of coils used in magnetic resonance experiments: Static magnetic field generation, RF-excitation and signal reception coils as well as coils to generate magnetic field gradients. In the first part, continuous proton hyperpolarization in aqueous solutions and using nicotinamide, a biomolecule, as the substrate was demonstrated. Due to its limits in in-vivo application, a high batch polarization was pursued in the second part. Additionally, a switch to nitrogen hyperpolarization was performed. A fully automated polarization and shuttling setup was designed and built. A magnetic fluxgate sensor was successfully fitted with custom readout electronics to work as a standalone device. For automation, a highly customizable setup embodying different kinds of valves and sensors was developed and built. Fluid handling schemes were established and manufactured in the workshop. The whole setup was built around a magnetic shielding allowing for the fields necessary for $^{15}$N hyperpolarization. Using the new assembly, polarizations in the single digit percent range were achieved using optimized parameters. $^{15}$N imaging quality was greatly improved by using this dedicated setup and optimized parameters compared to initial results. In future, the setup can be used to generate high magnetization batches of relevant molecules. The design is not limited to $^{15}$N polarization, but can be used as a high pressure polarization chamber in controlled magnetic fields for other hyperpolarization experiments as well.
